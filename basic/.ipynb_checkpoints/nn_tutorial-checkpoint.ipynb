{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "nn package\n",
    "==========\n",
    "\n",
    "We’ve redesigned the nn package, so that it’s fully integrated with\n",
    "autograd. Let's review the changes.\n",
    "\n",
    "**Replace containers with autograd:**\n",
    "\n",
    "    You no longer have to use Containers like ``ConcatTable``, or modules like\n",
    "    ``CAddTable``, or use and debug with nngraph. We will seamlessly use\n",
    "    autograd to define our neural networks. For example,\n",
    "\n",
    "    * ``output = nn.CAddTable():forward({input1, input2})`` simply becomes\n",
    "      ``output = input1 + input2``\n",
    "    * ``output = nn.MulConstant(0.5):forward(input)`` simply becomes\n",
    "      ``output = input * 0.5``\n",
    "\n",
    "**State is no longer held in the module, but in the network graph:**\n",
    "\n",
    "    Using recurrent networks should be simpler because of this reason. If\n",
    "    you want to create a recurrent network, simply use the same Linear layer\n",
    "    multiple times, without having to think about sharing weights.\n",
    "\n",
    "    .. figure:: /_static/img/torch-nn-vs-pytorch-nn.png\n",
    "       :alt: torch-nn-vs-pytorch-nn\n",
    "\n",
    "       torch-nn-vs-pytorch-nn\n",
    "\n",
    "**Simplified debugging:**\n",
    "\n",
    "    Debugging is intuitive using Python’s pdb debugger, and **the debugger\n",
    "    and stack traces stop at exactly where an error occurred.** What you see\n",
    "    is what you get.\n",
    "\n",
    "Example 1: ConvNet\n",
    "------------------\n",
    "\n",
    "Let’s see how to create a small ConvNet.\n",
    "\n",
    "All of your networks are derived from the base class ``nn.Module``:\n",
    "\n",
    "-  In the constructor, you declare all the layers you want to use.\n",
    "-  In the forward function, you define how your model is going to be\n",
    "   run, from input to output\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the defined ConvNet now.\n",
    "You create an instance of the class first.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><h4>Note</h4><p>``torch.nn`` only supports mini-batches The entire ``torch.nn``\n",
    "    package only supports inputs that are a mini-batch of samples, and not\n",
    "    a single sample.\n",
    "\n",
    "    For example, ``nn.Conv2d`` will take in a 4D Tensor of\n",
    "    ``nSamples x nChannels x Height x Width``.\n",
    "\n",
    "    If you have a single sample, just use ``input.unsqueeze(0)`` to add\n",
    "    a fake batch dimension.</p></div>\n",
    "\n",
    "Create a mini-batch containing a single sample of random data and send the\n",
    "sample through the ConvNet.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a dummy target label and compute error using a loss function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the ConvNet ``out`` is a ``Tensor``. We compute the loss\n",
    "using that, and that results in ``err`` which is also a ``Tensor``.\n",
    "Calling ``.backward`` on ``err`` hence will propagate gradients all the\n",
    "way through the ConvNet to it’s weights\n",
    "\n",
    "Let's access individual layer weights and gradients:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forward and Backward Function Hooks\n",
    "-----------------------------------\n",
    "\n",
    "We’ve inspected the weights and the gradients. But how about inspecting\n",
    "/ modifying the output and grad\\_output of a layer?\n",
    "\n",
    "We introduce **hooks** for this purpose.\n",
    "\n",
    "You can register a function on a ``Module`` or a ``Tensor``.\n",
    "The hook can be a forward hook or a backward hook.\n",
    "The forward hook will be executed when a forward call is executed.\n",
    "The backward hook will be executed in the backward phase.\n",
    "Let’s look at an example.\n",
    "\n",
    "We register a forward hook on conv2 and print some information\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We register a backward hook on conv2 and print some information\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A full and working MNIST example is located here\n",
    "https://github.com/pytorch/examples/tree/master/mnist\n",
    "\n",
    "Example 2: Recurrent Net\n",
    "------------------------\n",
    "\n",
    "Next, let’s look at building recurrent nets with PyTorch.\n",
    "\n",
    "Since the state of the network is held in the graph and not in the\n",
    "layers, you can simply create an nn.Linear and reuse it over and over\n",
    "again for the recurrence.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more complete Language Modeling example using LSTMs and Penn Tree-bank\n",
    "is located\n",
    "`here <https://github.com/pytorch/examples/tree/master/word\\_language\\_model>`_\n",
    "\n",
    "PyTorch by default has seamless CuDNN integration for ConvNets and\n",
    "Recurrent Nets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some fake data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# %%%%%%RUNNABLE_CODE_REMOVED%%%%%%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
